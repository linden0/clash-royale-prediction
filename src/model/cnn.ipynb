{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import random\n",
    "import wave\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wavs_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all WAV files in a folder, converts them to numpy arrays, and plots their waveforms.\n",
    "    \"\"\"\n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.wav'):  # Process only .wav files\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # Open the WAV file\n",
    "                wf = wave.open(file_path, 'rb')  \n",
    "\n",
    "                # Get audio parameters\n",
    "                nframes = wf.getnframes()\n",
    "                framerate = wf.getframerate()\n",
    "\n",
    "                # Read the audio data\n",
    "                audio_data = wf.readframes(nframes)\n",
    "                audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
    "                \n",
    "                # Normalize the data\n",
    "                audio_array = audio_array / (2 ** (wf.getsampwidth() * 8 - 1))\n",
    "\n",
    "                # Time axis for plotting\n",
    "                time_axis = np.arange(0, len(audio_array)) / framerate\n",
    "\n",
    "                # Plot the waveform\n",
    "                plt.figure(figsize=(10, 4))\n",
    "                plt.plot(time_axis, audio_array)\n",
    "                plt.xlabel(\"Time (seconds)\")\n",
    "                plt.ylabel(\"Amplitude\")\n",
    "                plt.title(f\"Waveform: {filename}\")\n",
    "                plt.grid()\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "# Provide the folder path containing the .wav files\n",
    "# folder_path = '../data/archers/'\n",
    "# plot_wavs_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found classes: ['_silence', 'archers', 'arrows', 'fireball', 'giant', 'knight', 'mini_pekka', 'minions', 'musketeer']\n",
      "Total examples: 395\n"
     ]
    }
   ],
   "source": [
    "def gather_data(data_root):\n",
    "    \"\"\"\n",
    "    Scans `data_root` directory. Each subfolder is a class label.\n",
    "    Returns:\n",
    "      - all_files: list of (wav_path, label_index) pairs\n",
    "      - classes: list of class names (strings) in sorted order\n",
    "    \"\"\"\n",
    "    classes = sorted(os.listdir(data_root))\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    \n",
    "    all_files = []\n",
    "    for cls_name in classes:\n",
    "        cls_folder = os.path.join(data_root, cls_name)\n",
    "        # Gather all WAV files in this folder\n",
    "        wav_files = glob.glob(os.path.join(cls_folder, \"*.wav\"))\n",
    "        for wav_file in wav_files:\n",
    "            all_files.append((wav_file, class_to_idx[cls_name]))\n",
    "    \n",
    "    return all_files, classes\n",
    "\n",
    "\n",
    "data_root = \"../../data\"  # Path to your data folder\n",
    "all_files, classes = gather_data(data_root)\n",
    "num_classes = len(classes)\n",
    "print(\"Found classes:\", classes)\n",
    "print(\"Total examples:\", len(all_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 316\n",
      "Val   size: 79\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(all_files)  # Shuffle in-place\n",
    "\n",
    "split_idx = int(0.8 * len(all_files))  # 80% for train\n",
    "train_files = all_files[:split_idx]\n",
    "val_files   = all_files[split_idx:]\n",
    "\n",
    "print(f\"Train size: {len(train_files)}\")\n",
    "print(f\"Val   size: {len(val_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, file_list, n_mfcc=12, sr=16000, augment=False):\n",
    "        \"\"\"\n",
    "        file_list: list of (wav_path, label_index)\n",
    "        n_mfcc: number of MFCC coefficients\n",
    "        sr: sample rate to which audio is (optionally) resampled\n",
    "        augment: if True, apply random augmentations to training data\n",
    "        \"\"\"\n",
    "        self.file_list = file_list\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.sr = sr\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wav_path, label = self.file_list[idx]\n",
    "        \n",
    "        # Load audio\n",
    "        waveform, sr = librosa.load(wav_path, sr=self.sr)\n",
    "\n",
    "        # Trim silence\n",
    "        if label != classes.index('_silence'):\n",
    "            waveform, _ = librosa.effects.trim(waveform, top_db=20)\n",
    "\n",
    "\n",
    "        # If augment is enabled, apply random transformations\n",
    "        if self.augment and len(waveform) > 2048:\n",
    "            # Random time-stretch (speed up/down by up to +/-10%)\n",
    "            if random.random() < 0.5:\n",
    "                rate = 1.0 + np.random.uniform(-0.1, 0.1)  # e.g., 0.9 to 1.1\n",
    "                waveform = librosa.effects.time_stretch(waveform, rate=rate)\n",
    "\n",
    "            # Random pitch shift (up/down by up to +/-2 semitones)\n",
    "            if random.random() < 0.5:\n",
    "                \n",
    "                n_steps = np.random.uniform(-2, 2)\n",
    "                waveform = librosa.effects.pitch_shift(waveform, sr=sr, n_steps=n_steps)\n",
    "\n",
    "            # Random time shift\n",
    "            # For example, shift by up to 10% of the wave length\n",
    "            if random.random() < 0.5:\n",
    "                shift_max = int(0.1 * len(waveform))\n",
    "                shift = np.random.randint(-shift_max, shift_max)\n",
    "                waveform = np.roll(waveform, shift)\n",
    "\n",
    "            # Random background noise injection\n",
    "            if random.random() < 0.5:\n",
    "                noise_level = np.random.uniform(0.01, 0.02)  # Adjust range as needed\n",
    "                noise = np.random.randn(len(waveform)) * noise_level\n",
    "                waveform = waveform + noise\n",
    "\n",
    "        # Now compute MFCC\n",
    "        mfcc = librosa.feature.mfcc(y=waveform, sr=sr, n_mfcc=self.n_mfcc, n_fft=1024)\n",
    "        mfcc = mfcc.T  # shape: (time_frames, n_mfcc)\n",
    "\n",
    "        # Convert to tensors\n",
    "        mfcc_tensor = torch.tensor(mfcc, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return mfcc_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of (mfcc_tensor, label_tensor) pairs\n",
    "    We pad MFCC tensors on the time dimension (dim=0) so they have the same length.\n",
    "    \"\"\"\n",
    "    mfccs = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    # Find max sequence length in this batch\n",
    "    max_len = max(m.shape[0] for m in mfccs)\n",
    "    n_mfcc  = mfccs[0].shape[1]  # number of MFCC coefficients\n",
    "\n",
    "    padded_mfccs = []\n",
    "    for m in mfccs:\n",
    "        length = m.shape[0]\n",
    "        pad_length = max_len - length\n",
    "        if pad_length > 0:\n",
    "            pad = torch.zeros(pad_length, n_mfcc)\n",
    "            m = torch.cat([m, pad], dim=0)\n",
    "        padded_mfccs.append(m)\n",
    "\n",
    "    # Stack along batch dimension\n",
    "    padded_mfccs = torch.stack(padded_mfccs, dim=0)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    return padded_mfccs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8  # Small batch size, given few examples per class\n",
    "\n",
    "train_dataset = SpeechCommandsDataset(train_files, n_mfcc=12, sr=16000, augment=True)\n",
    "val_dataset   = SpeechCommandsDataset(val_files,   n_mfcc=12, sr=16000, augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          collate_fn=collate_fn)\n",
    "\n",
    "val_loader   = DataLoader(val_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False,\n",
    "                          collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linden/Desktop/projects/cr_prediction/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes, in_channels=1):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Example: a small, 3-layer CNN\n",
    "        # You can increase depth/channels for better performance\n",
    "        # but be mindful of overfitting if the dataset is small.\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # halve time and mfcc dims\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),  # halve time and mfcc dims\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # Optionally another pooling\n",
    "            # nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        # After the last conv, we do adaptive average pooling so that\n",
    "        # we get a fixed-size 2D feature map, regardless of input time dimension.\n",
    "        # Then we flatten and do a fully connected layer to classify.\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier  = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is originally (batch_size, time, n_mfcc)\n",
    "        # We need to add a channel dimension => (batch_size, 1, time, n_mfcc)\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        # Pass through convolutional layers\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Global average pooling -> (batch_size, 64, 1, 1)\n",
    "        x = self.global_pool(x)\n",
    "        \n",
    "        # Flatten -> (batch_size, 64)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Classify\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "input_size = 12      # Because we used n_mfcc=12\n",
    "hidden_size = 48     # Hyperparameter - tune as needed\n",
    "num_layers = 2       # Hyperparameter - tune as needed\n",
    "learning_rate = 1e-3\n",
    "model = CNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for mfccs, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
    "        mfccs, labels = mfccs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(mfccs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * mfccs.size(0)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for mfccs, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            mfccs, labels = mfccs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(mfccs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * mfccs.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_loss = running_loss / total\n",
    "    val_acc  = correct / total\n",
    "    return val_loss, val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d9a754b09e49cda1e4d501fd729d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78b632f00f44addb6fb269f8001ac7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5298  |  Train Acc: 0.8481\n",
      "Val   Loss: 0.1746  |  Val   Acc: 0.9873\n",
      "\n",
      "Epoch [2/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6aeb753faee4b3f81c28e4e88f35821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5486f0f06b4e40bb0add49f93edf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6642  |  Train Acc: 0.7848\n",
      "Val   Loss: 0.1136  |  Val   Acc: 1.0000\n",
      "\n",
      "Epoch [3/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aead8f4f5c244264a7d27c20ea80b4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f6dce0a59144fb970660825fed9226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5626  |  Train Acc: 0.8165\n",
      "Val   Loss: 0.2033  |  Val   Acc: 0.9114\n",
      "\n",
      "Epoch [4/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65a6a8b268b415da5d5d84b002c1c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49b9df64d674652b5dfe02831959d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5641  |  Train Acc: 0.8323\n",
      "Val   Loss: 0.1487  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [5/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e0a847e90d42a1b1a6415f034e8bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75f2f6c4efa4a33879f55ec081c3b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4603  |  Train Acc: 0.8354\n",
      "Val   Loss: 0.1605  |  Val   Acc: 0.9620\n",
      "\n",
      "Epoch [6/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8e673bccea4628bd0e1bf25e0c3cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ed18ed34a34a37bcd62cf6e17f8746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5783  |  Train Acc: 0.8006\n",
      "Val   Loss: 0.0977  |  Val   Acc: 0.9873\n",
      "\n",
      "Epoch [7/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4e325d47d94022b942f55170d66673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8563e20d636541f9844fbeadd3f270d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4947  |  Train Acc: 0.8386\n",
      "Val   Loss: 0.1091  |  Val   Acc: 0.9873\n",
      "\n",
      "Epoch [8/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611bc6836d0947d2aa45d505f38b162e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaafb69fd28843119238f033a682a18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4870  |  Train Acc: 0.8513\n",
      "Val   Loss: 0.1389  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [9/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0c0afcbf7041029c5b6031f673f683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc166a046f74ae39fa80f2f6a49154f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5812  |  Train Acc: 0.8354\n",
      "Val   Loss: 0.1064  |  Val   Acc: 1.0000\n",
      "\n",
      "Epoch [10/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e758d457163c4ac2a9fffc141010e298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffdb2dbbe874f3f9588169eb7bfc182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5763  |  Train Acc: 0.8070\n",
      "Val   Loss: 0.1015  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [11/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7d243138adb410897652494b48a9811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11a201587bf475eb74bc2fe1459c2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4877  |  Train Acc: 0.8576\n",
      "Val   Loss: 0.1642  |  Val   Acc: 0.9620\n",
      "\n",
      "Epoch [12/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe655a391dd74d46bea581bb0d553597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8453bb1a2140668ff4277c4c525a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5096  |  Train Acc: 0.8228\n",
      "Val   Loss: 0.1687  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [13/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baedeae23aa543ed997ea342b9b5fa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1c344ea6a749fb89c5c27337e502ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4758  |  Train Acc: 0.8576\n",
      "Val   Loss: 0.1065  |  Val   Acc: 0.9620\n",
      "\n",
      "Epoch [14/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c579fa3ee94727b29bb0322e131cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4406d13e45d246479f29fbd0e3d86ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5176  |  Train Acc: 0.8323\n",
      "Val   Loss: 0.1513  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [15/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607f24efe0594c24ac3493d3ee6e2904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff3cb04131e4de7b2c20c2c7b2bb4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4639  |  Train Acc: 0.8608\n",
      "Val   Loss: 0.1679  |  Val   Acc: 0.9620\n",
      "\n",
      "Epoch [16/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5055bdfe4e840ed8467fcad2420c531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c8725662d1416b80c6748b68c8eda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4866  |  Train Acc: 0.8323\n",
      "Val   Loss: 0.1821  |  Val   Acc: 0.9367\n",
      "\n",
      "Epoch [17/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a136c4bc244491839ea75f7aaba9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58740f0135042e68daaa90d6f8ffbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4716  |  Train Acc: 0.8576\n",
      "Val   Loss: 0.1097  |  Val   Acc: 0.9494\n",
      "\n",
      "Epoch [18/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98df6d906f924de78197d5d6304cd946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77e98cd1708459ebe9a11c329fbabb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4424  |  Train Acc: 0.8671\n",
      "Val   Loss: 0.2188  |  Val   Acc: 0.9367\n",
      "\n",
      "Epoch [19/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4019a3bd8d4aec94479d2c9570a031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1439e6ced4d948e2b1e2ee702aba2e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4883  |  Train Acc: 0.8576\n",
      "Val   Loss: 0.1613  |  Val   Acc: 0.9620\n",
      "\n",
      "Epoch [20/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492e028c589642fc9587d0ae6429d905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23a3c930a044c058ad3b6b2b525a19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5134  |  Train Acc: 0.8513\n",
      "Val   Loss: 0.1511  |  Val   Acc: 0.9620\n",
      "\n",
      "Epoch [21/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9984a6dd84b64127a6dd28aa7aea0681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1cde6f590c47c1bb355ca20e773a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3948  |  Train Acc: 0.8671\n",
      "Val   Loss: 0.1398  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [22/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ff728478104786a8b716bea9020a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5725ca42d040ecb2d2129f13310256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5120  |  Train Acc: 0.8291\n",
      "Val   Loss: 0.0890  |  Val   Acc: 1.0000\n",
      "\n",
      "Epoch [23/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c118b355a20c4f72b6d296e5cd21c0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944c3eb51ea44dc6bb17f64b16c17ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4669  |  Train Acc: 0.8639\n",
      "Val   Loss: 0.0791  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [24/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4d2a167fab40c0a652c4a128a8b508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5984dd8416bb4aa5a9fadd3d122b4b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4780  |  Train Acc: 0.8323\n",
      "Val   Loss: 0.1262  |  Val   Acc: 0.9747\n",
      "\n",
      "Epoch [25/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b7782b08df451e88d52223a3681557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f9276189eb4081b880925948a28879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4918  |  Train Acc: 0.8386\n",
      "Val   Loss: 0.1130  |  Val   Acc: 0.9873\n",
      "\n",
      "Epoch [26/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d318441504944d3ab6735f4858a3fa34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c27724b1b024c5eb0c0b0d7c0350358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4454  |  Train Acc: 0.8481\n",
      "Val   Loss: 0.1466  |  Val   Acc: 0.9494\n",
      "\n",
      "Epoch [27/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192c0783839145d38fc15deac85ebda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6b337e547c45eab87182f449314fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3641  |  Train Acc: 0.8829\n",
      "Val   Loss: 0.1501  |  Val   Acc: 0.9494\n",
      "\n",
      "Epoch [28/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59595965bcf14d1c84df780a79d2f9a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c00bbc219e466db3d4e06a7e5c64d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4500  |  Train Acc: 0.8449\n",
      "Val   Loss: 0.1579  |  Val   Acc: 0.9494\n",
      "\n",
      "Epoch [29/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9c2622dcc54111b0b246d598984bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e94984a30214ccc8923f945b81a1711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4304  |  Train Acc: 0.8544\n",
      "Val   Loss: 0.0767  |  Val   Acc: 0.9873\n",
      "\n",
      "Epoch [30/30]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66a9d22cc6f4c2da9e91d32db573e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06729b2de7404330bc6e024f91cdbb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5056  |  Train Acc: 0.8418\n",
      "Val   Loss: 0.1341  |  Val   Acc: 0.9747\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "best_loss = float(\"inf\")\n",
    "best_model_weights = None\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_model_weights = model.state_dict()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}  |  Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}  |  Val   Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07674016758705242"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_weights, \"cnn_model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, wav_path, classes, device='cuda', sr=16000, n_mfcc=12):\n",
    "    \"\"\"\n",
    "    Predict the class for a single .wav audio file.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained PyTorch model.\n",
    "        wav_path (str): Path to the .wav file.\n",
    "        classes (list): List of class names (strings), where index=label.\n",
    "        device (str): 'cpu' or 'cuda' device.\n",
    "        sr (int): Sample rate to which the audio is (optionally) resampled.\n",
    "        n_mfcc (int): Number of MFCC features to compute.\n",
    "\n",
    "    Returns:\n",
    "        predicted_label (str): The predicted class name.\n",
    "        confidence (float): Softmax confidence for the predicted class.\n",
    "    \"\"\"\n",
    "    model.load_state_dict(torch.load(\"/home/linden/Desktop/projects/cr_prediction/src/model/cnn_model.pt\", map_location=device))\n",
    "\n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Load and preprocess audio\n",
    "    waveform, sr = librosa.load(wav_path, sr=sr)       # waveform: float32 numpy array\n",
    "    mfcc = librosa.feature.mfcc(y=waveform, sr=sr, n_mfcc=n_mfcc, n_fft=1024)  # shape: (n_mfcc, time_frames)\n",
    "    mfcc = mfcc.T  # shape: (time_frames, n_mfcc)\n",
    "    \n",
    "    # Convert to Torch tensor, add batch dimension => (1, time_frames, n_mfcc)\n",
    "    mfcc_tensor = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        outputs = model(mfcc_tensor)  # shape: (1, num_classes)\n",
    "        \n",
    "        # Optionally compute softmax to get probabilities\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Get predicted class index and its confidence\n",
    "        predicted_idx = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0, predicted_idx].item()\n",
    "\n",
    "    # Map index back to class label\n",
    "    predicted_label = classes[predicted_idx]\n",
    "    \n",
    "    return predicted_label, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28629/3670507869.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/home/linden/Desktop/projects/cr_prediction/src/model/cnn_model.pt\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('fireball', 0.8811231851577759)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model=model, wav_path='/home/linden/Desktop/projects/cr_prediction/vad_segments/6.wav', classes=classes, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_window_inference(\n",
    "    model,\n",
    "    audio_array,\n",
    "    sr,\n",
    "    classes,\n",
    "    window_size=1.0,   # seconds\n",
    "    hop_size=0.5,      # seconds\n",
    "    n_mfcc=12,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform chunk-based inference on a long audio array.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): Trained LSTM model that classifies short segments.\n",
    "        audio_array (np.ndarray): 1D float array of audio samples.\n",
    "        sr (int): Sample rate of the audio.\n",
    "        classes (list[str]): List of class labels (index -> label).\n",
    "        window_size (float): Duration (seconds) of each chunk.\n",
    "        hop_size (float): Step size (seconds) between chunks.\n",
    "        n_mfcc (int): Number of MFCC coefficients to compute per chunk.\n",
    "        device (str): 'cpu' or 'cuda'.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples (start_time, end_time, predicted_label, confidence).\n",
    "        - start_time and end_time are float seconds indicating the chunk.\n",
    "        - predicted_label is the string label predicted.\n",
    "        - confidence is the softmax probability for that label.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert window/hop from seconds to samples\n",
    "    window_length = int(window_size * sr)\n",
    "    hop_length = int(hop_size * sr)\n",
    "    \n",
    "    # We'll slide from start=0 up to len(audio_array) - window_length (inclusive)\n",
    "    outputs = []\n",
    "    start = 0\n",
    "    \n",
    "    while start + window_length <= len(audio_array):\n",
    "        end = start + window_length\n",
    "        chunk = audio_array[start:end]\n",
    "        \n",
    "        # Compute MFCC for this chunk\n",
    "        mfcc = librosa.feature.mfcc(y=chunk, sr=sr, n_mfcc=n_mfcc)  # (n_mfcc, time_frames)\n",
    "        mfcc = mfcc.T  # (time_frames, n_mfcc)\n",
    "\n",
    "        # Convert to torch tensor with shape (1, time_frames, n_mfcc)\n",
    "        mfcc_tensor = torch.tensor(mfcc, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model(mfcc_tensor)  # shape: (1, num_classes)\n",
    "            probs = torch.softmax(logits, dim=1).squeeze(0)  # (num_classes,)\n",
    "            pred_idx = torch.argmax(probs).item()\n",
    "            confidence = probs[pred_idx].item()\n",
    "            label = classes[pred_idx]\n",
    "        \n",
    "        # Convert sample indices to time\n",
    "        start_time_sec = start / sr\n",
    "        end_time_sec = end / sr\n",
    "        \n",
    "        if confidence > 0.5:\n",
    "          outputs.append((start_time_sec, end_time_sec, label, confidence))\n",
    "        \n",
    "        # Slide the window by hop_length\n",
    "        start += hop_length\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"../data/test/2.wav\", sr=16000)\n",
    "sliding_window_inference(model, y, sr, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/home/linden/Desktop/projects/cr_prediction/test.wav'\n",
    "audio, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(audio, sr=sr)\n",
    "plt.title('Audio Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = '/home/linden/Desktop/projects/cr_prediction/output.wav'\n",
    "audio, sr = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.waveshow(audio, sr=sr)\n",
    "plt.title('Audio Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
